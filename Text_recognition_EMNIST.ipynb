{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_8oX-SV0WR7u"
   },
   "source": [
    "# Свёрточная нейронная сеть для распознавания рукописного текста"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UjS_16t4V4xQ"
   },
   "source": [
    "## Цель работы\n",
    "\n",
    "Построить свёрточную нейронную сеть (CNN) для задачи распознавания рукописных символов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qyd1ULaEQUkF"
   },
   "source": [
    "## Ход работы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NGDMVa92VZ0y"
   },
   "source": [
    "Распознавание почерка, или так называемая классификация рукописных документов, является сложной задачей из-за огромной вариативности индивидуальных стилей письма. Традиционный подход к решению этой проблемы заключается в извлечении языковых признаков, таких как кривизна различных букв, расстояние между буквами и т.д.\n",
    "\n",
    "В данной работе для выявления этих особенностей будет использована сверточная нейронная сеть (CNN)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D2wHSTq3kalg"
   },
   "source": [
    "### Импортируем необходимые библиотеки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "mmZ5_5a1kb4L",
    "outputId": "700f42c4-240b-42f3-8fb9-e3aaa6543253"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/device:CPU:0']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "#os.environ['CUDA_VISIBLE_DEVICES'] = '' # hides the GPU from tensorflow (for science)\n",
    "import gzip\n",
    "import tensorflow.keras\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "import struct\n",
    "import time\n",
    "\n",
    "#List computing devices available to tensorflow:\n",
    "from tensorflow.python.client import device_lib\n",
    "device_list = device_lib.list_local_devices()\n",
    "[x.name for x in device_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sibyQMGLlOJL"
   },
   "source": [
    "### Загружаем датасет"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1frn3hdvWiDO"
   },
   "source": [
    "В данной работе для обучения и тестирования использовался набор данных EMNIST, представляющий собой набор рукописных символов, полученных из специальной базы данных NIST 19 и преобразованных в формат изображения 28×28 пикселей - структуру набора данных, которая непосредственно соответствует набору данных MNIST. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "ZliPnaJ3kdfT"
   },
   "outputs": [],
   "source": [
    "#List computing devices available to tensor-flow:\n",
    "%matplotlib inline\n",
    "random.seed(12345)\n",
    "image_dir = '/content/drive/MyDrive/Colab Notebooks/data/gzip/'\n",
    "labels = '0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz'\n",
    "categories = len(labels)\n",
    "batch_size = 1024\n",
    "epochs = 10\n",
    "model_path = '/content/drive/MyDrive/Colab Notebooks/models_EMNIST'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "PDxm_9AcphSK",
    "outputId": "08671106-d801-4dbf-9b81-141103ecf88a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting emnist\n",
      "  Downloading emnist-0.0-py3-none-any.whl (7.3 kB)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from emnist) (2.23.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from emnist) (1.19.5)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from emnist) (4.62.3)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->emnist) (1.24.3)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->emnist) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->emnist) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->emnist) (2021.10.8)\n",
      "Installing collected packages: emnist\n",
      "Successfully installed emnist-0.0\n"
     ]
    }
   ],
   "source": [
    "#Install EMIST library, import datasets of letters, Matplotlib\n",
    "# !pip install emnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "BlEKFX7xmgqu"
   },
   "outputs": [],
   "source": [
    "from emnist import list_datasets\n",
    "from emnist import extract_training_samples\n",
    "from emnist import extract_test_samples\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "MK7M5zJ_p9Mk",
    "outputId": "c62474c5-91e4-4891-fff7-f971e4df8aea"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading emnist.zip: 536MB [00:08, 68.5MB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['balanced', 'byclass', 'bymerge', 'digits', 'letters', 'mnist']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Download dataset and it is 536 MB\n",
    "list_datasets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "4kFd8xvFqCSz",
    "outputId": "c378e995-7e8f-49a6-aa8d-4eaf70c190c1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(697932, 28, 28)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Download images of letters from training samples or test samples\n",
    "#from emnist import extract_test_samples\n",
    "raw_train_X, raw_train_y = extract_training_samples('byclass')\n",
    "raw_train_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "ewLankEgtIzg",
    "outputId": "b1a2ddf2-af48-4c9c-8bf4-4cd071047878"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(697932,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_train_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "ED47bVLowMSl",
    "outputId": "261e0d5c-1264-4a92-b98e-8dd0b2161b0d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "       17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n",
       "       34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50,\n",
       "       51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61], dtype=uint8)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(raw_train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "xDOgq2CFsk4z",
    "outputId": "dc718ddd-4b34-4ae3-d73a-ee3293590d3b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(116323, 28, 28)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_test_X, raw_test_y = extract_test_samples('byclass')\n",
    "raw_test_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "UMp7GyVWtMB2",
    "outputId": "9fda43c8-25fe-4808-d209-7d706c8bf7cd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(116323,)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_test_y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GAlibsTRtcsI"
   },
   "source": [
    "Выведем случайное изображение, чтобы убедиться, что данные считаны корректно:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286
    },
    "id": "c5yeYn-HrxvE",
    "outputId": "4c267cce-47eb-4eb8-9fce-b5c36fd002b3"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "i = random.randint(0, raw_train_X.shape[0])\n",
    "fig, ax = plt.subplots()\n",
    "ax.clear()\n",
    "ax.imshow(raw_train_X[i], cmap='gray')\n",
    "title = 'label = %d = %s' % (raw_train_y[i], labels[raw_train_y[i]])\n",
    "ax.set_title(title, fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JKt3Qr9CxTKv"
   },
   "source": [
    "### Предобработка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e6nqF8F3Xhtw"
   },
   "source": [
    "Предварительная обработка набора данных EMNIST включает нормализацию входных данных для обучения и тестирования, изменение формы входных данных для ввода в CNN и one-hot кодирование выходных данных (меток)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "YmFfkkjVxUsL"
   },
   "outputs": [],
   "source": [
    "train_X = raw_train_X.astype('float32')\n",
    "test_X = raw_test_X.astype('float32')\n",
    "train_X /= 255\n",
    "test_X /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "rRR6WEPdxX3s"
   },
   "outputs": [],
   "source": [
    "train_X = train_X.reshape(train_X.shape[0], 28, 28, 1)\n",
    "test_X = test_X.reshape(test_X.shape[0], 28, 28, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "ZLerDPpVxaAf"
   },
   "outputs": [],
   "source": [
    "train_y = tensorflow.keras.utils.to_categorical(raw_train_y)\n",
    "test_y = tensorflow.keras.utils.to_categorical(raw_test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JUyu8b6-xdU3"
   },
   "source": [
    "### Задаём модель нейронной сети"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cKviGfxAX57B"
   },
   "source": [
    "Для этой задачи мы построим сверточную нейронную сеть (CNN) в Keras с использованием бэкенда Tensorflow. Мы будем использовать стандартную CNN с несколькими слоями свертки и Maxpool, несколькими плотными слоями и финальным выходным слоем с активацией softmax. Между сверточным и плотным слоями использовалась активация RELU, а модель была оптимизирована с помощью оптимизатора Adam."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d-tiKI5cXDq3"
   },
   "source": [
    "Входное изображение подается на слои CNN. Эти слои обучаются извлекать соответствующие признаки из изображения. Каждый слой состоит из трех операций. Во-первых, операция свертки, при которой к входному изображению применяется ядро фильтра размером 5×5 в первых двух слоях и 3×3 в последних трех слоях. Затем применяется нелинейная функция RELU. Наконец, слой объединения суммирует области изображения и выдает уменьшенную версию входного сигнала. Пока высота изображения уменьшается в 2 раза в каждом слое, добавляются карты признаков (каналы), так что выходная карта признаков (или последовательность) имеет размер 32×256."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "0owm77oyxewv"
   },
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "model = tensorflow.keras.models.Sequential()\n",
    "model.add(tensorflow.keras.layers.Conv2D(32,\n",
    "                kernel_size=(5, 5),\n",
    "                strides=(2, 2),\n",
    "                input_shape=(28, 28, 1),\n",
    "                activation='relu'))\n",
    "model.add(tensorflow.keras.layers.Conv2D(64,\n",
    "                kernel_size=(3, 3),\n",
    "                activation='relu'))\n",
    "model.add(tensorflow.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(tensorflow.keras.layers.Dropout(0.25))\n",
    "model.add(tensorflow.keras.layers.Flatten())\n",
    "model.add(tensorflow.keras.layers.Dense(128, activation='relu'))\n",
    "model.add(tensorflow.keras.layers.Dropout(0.25))\n",
    "model.add(tensorflow.keras.layers.Dense(categories, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "l3oanSMyyFME"
   },
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1shTf-qdxkXT"
   },
   "source": [
    "### Обучаем модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nFm9GpqixlV2",
    "outputId": "f4c79ace-a69a-4fa1-c626-aa52cea624bd"
   },
   "outputs": [],
   "source": [
    "# t1 = time.time()\n",
    "# fit = model.fit(train_X, train_y, batch_size=batch_size, epochs=30, verbose=1, validation_data=(test_X, test_y))\n",
    "# t2 = time.time()\n",
    "# print('Elapsed time: %ds' % (t2 - t1))\n",
    "# model.save('/content/drive/MyDrive/Colab Notebooks/models_EMNIST/emnist_letters_30epochs.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "ODbSzr5OQD9-"
   },
   "outputs": [],
   "source": [
    "model = tensorflow.keras.models.load_model('/content/drive/MyDrive/Colab Notebooks/models_EMNIST/emnist_letters_30epochs.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X4EJONtbR_6l"
   },
   "source": [
    "### Тестирование модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "EDLmNkTlRqNK",
    "outputId": "2dbd22fe-453c-4ca7-9182-5122f1007f40"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3636/3636 [==============================] - 26s 7ms/step - loss: 0.3420 - accuracy: 0.8726\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(test_X, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "QKWR4lJpSikl",
    "outputId": "56531736-456e-4708-f97a-cc077f137f41"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34.19691622257233 87.25789189338684\n"
     ]
    }
   ],
   "source": [
    "print(results[0]*100, results[1]*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SO0QKYN_UR0D"
   },
   "source": [
    "## Выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zolKW-IhUV0f"
   },
   "source": [
    "Точность распознавания текста составила 87,2 % при потерях 34,2 %.\n",
    "\n",
    "Распознавание рукописного текста с помощью глубокого обучения - очень мощная техника по нескольким причинам:\n",
    "\n",
    "* Оно автоматически идентифицирует глубокие мощные признаки\n",
    "* Наш подход, заключающийся в подаче случайных участков, делает модель независимой от текста\n",
    "* Высокая точность предсказания позволяет использовать ее в практических приложениях"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Text_recognition_EMNIST.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
